{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from msclap import CLAP\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 42, 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_classes = list(sorted(os.listdir(\"D:/DATA/UCF-101-SEEN/test_seen/\")))\n",
    "unseen_classes = list(sorted(os.listdir(\"D:/DATA/UCF-101-SEEN/test_unseen/\")))\n",
    "all_classes = list(sorted(seen_classes + unseen_classes))\n",
    "len(all_classes), len(seen_classes), len(unseen_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BasketballDunk',\n",
       " 'BlowDryHair',\n",
       " 'BlowingCandles',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BrushingTeeth',\n",
       " 'CliffDiving',\n",
       " 'CricketBowling',\n",
       " 'CricketShot',\n",
       " 'CuttingInKitchen',\n",
       " 'FieldHockeyPenalty',\n",
       " 'FloorGymnastics',\n",
       " 'FrisbeeCatch',\n",
       " 'FrontCrawl',\n",
       " 'Haircut',\n",
       " 'HammerThrow',\n",
       " 'Hammering',\n",
       " 'HandStandPushups',\n",
       " 'HandstandWalking',\n",
       " 'HeadMassage',\n",
       " 'IceDancing',\n",
       " 'Knitting',\n",
       " 'LongJump',\n",
       " 'MoppingFloor',\n",
       " 'ParallelBars',\n",
       " 'PlayingCello',\n",
       " 'PlayingDaf',\n",
       " 'PlayingDhol',\n",
       " 'PlayingFlute',\n",
       " 'PlayingSitar',\n",
       " 'Rafting',\n",
       " 'ShavingBeard',\n",
       " 'Shotput',\n",
       " 'SkyDiving',\n",
       " 'SoccerPenalty',\n",
       " 'StillRings',\n",
       " 'SumoWrestling',\n",
       " 'Surfing',\n",
       " 'TableTennisShot',\n",
       " 'Typing',\n",
       " 'UnevenBars',\n",
       " 'WallPushups',\n",
       " 'WritingOnBoard']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_class_to_idx = {C: i for i, C in enumerate(seen_classes)}\n",
    "unseen_class_to_idx = {C: i for i, C in enumerate(unseen_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_to_idx = {C: i for i, C in enumerate(all_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDataLoader(object):\n",
    "\n",
    "    def __init__(self, root: str, task: str, batch_size: int, class_to_idx: dict[str, int], shuffle: bool = True):\n",
    "\n",
    "        root = os.path.join(root, task)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.audio_paths = []\n",
    "        self.labels = []\n",
    "        for C in os.listdir(root):\n",
    "            class_dir = os.path.join(root, C)\n",
    "            for file in os.listdir(class_dir):\n",
    "                assert(file[:file.index('_')] == C)\n",
    "                self.audio_paths.append(os.path.join(class_dir, file))\n",
    "                self.labels.append(class_to_idx[C])\n",
    "\n",
    "        self.indices = np.arange(len(self.audio_paths))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "        self.next_ptr = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.indices) / self.batch_size))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> tuple[list[str], list[int]]:\n",
    "        if self.next_ptr >= len(self.indices):\n",
    "            self.next_ptr = 0\n",
    "            raise StopIteration\n",
    "        \n",
    "        batch_paths = []\n",
    "        batch_labels = []\n",
    "        for _ in range(self.batch_size):\n",
    "            if self.next_ptr >= len(self.indices):\n",
    "                break\n",
    "\n",
    "            index = self.indices[self.next_ptr]\n",
    "            self.next_ptr += 1\n",
    "\n",
    "            batch_paths.append(self.audio_paths[index])\n",
    "            batch_labels.append(self.labels[index])\n",
    "        \n",
    "        return batch_paths, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]\n",
    "\n",
    "def inference(model: CLAP, classes: list[int], loader: FileDataLoader, device: str):\n",
    "    top1, top3, top5 = 0, 0, 0\n",
    "    text_embeddings = model.get_text_embeddings([f\"a photo of a {c}\"for c in classes])\n",
    "\n",
    "    num_ttl = 0\n",
    "    for paths, labels in tqdm(loader, total=len(loader), leave=False):\n",
    "\n",
    "        audio_embeddings = model.get_audio_embeddings(paths)\n",
    "        similarity = model.compute_similarity(audio_embeddings, text_embeddings).softmax(dim=1)\n",
    "        \n",
    "        labels = torch.tensor(labels).to(device)\n",
    "        acc1, acc3, acc5 = accuracy(similarity, labels, topk=(1, 3, 5))\n",
    "        top1 += acc1\n",
    "        top3 += acc3\n",
    "        top5 += acc5\n",
    "\n",
    "        num_ttl += len(paths)\n",
    "\n",
    "    return top1 / num_ttl, top1, top3 / num_ttl, top3, top5 / num_ttl, top5, num_ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"D:/DATA/UCF101-Waves-Raw/\"\n",
    "\n",
    "# train_loader = FileDataLoader(ROOT, \"train\", 4, seen_class_to_idx)\n",
    "# test_seen_loader = FileDataLoader(ROOT, \"test_seen\", 4, seen_class_to_idx)\n",
    "# test_unseen_loader = FileDataLoader(ROOT, \"test_unseen\", 4, unseen_class_to_idx)\n",
    "\n",
    "train_loader = FileDataLoader(ROOT, \"train\", 4, all_class_to_idx)\n",
    "test_seen_loader = FileDataLoader(ROOT, \"test_seen\", 4, all_class_to_idx)\n",
    "test_unseen_loader = FileDataLoader(ROOT, \"test_unseen\", 4, all_class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset\n",
      "Top-1 accuracy: 20.162%, correct: 1793/8893\n",
      "Top-3 accuracy: 36.984%, correct: 3289/8893\n",
      "Top-5 accuracy: 48.960%, correct: 4354/8893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Load and initialize CLAP\n",
    "    clap_model = CLAP(version = '2023', use_cuda=True)\n",
    "    # top1_acc, top1, top3_acc, top3, top5_acc, top5, num_ttl = inference(clap_model, seen_classes, train_loader, \"cuda\")\n",
    "    top1_acc, top1, top3_acc, top3, top5_acc, top5, num_ttl = inference(clap_model, all_classes, train_loader, \"cuda\")\n",
    "    print(\"train_dataset\")\n",
    "    print(f\"Top-1 accuracy: {top1_acc:.3%}, correct: {int(top1)}/{num_ttl}\")\n",
    "    print(f\"Top-3 accuracy: {top3_acc:.3%}, correct: {int(top3)}/{num_ttl}\")\n",
    "    print(f\"Top-5 accuracy: {top5_acc:.3%}, correct: {int(top5)}/{num_ttl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_seen_dataset\n",
      "Top-1 accuracy: 20.348%, correct: 187/919\n",
      "Top-3 accuracy: 42.873%, correct: 394/919\n",
      "Top-5 accuracy: 55.060%, correct: 506/919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Load and initialize CLAP\n",
    "    clap_model = CLAP(version = '2023', use_cuda=True)\n",
    "    top1_acc, top1, top3_acc, top3, top5_acc, top5, num_ttl = inference(clap_model, seen_classes, test_seen_loader, \"cuda\")\n",
    "    print(\"test_seen_dataset\")\n",
    "    print(f\"Top-1 accuracy: {top1_acc:.3%}, correct: {int(top1)}/{num_ttl}\")\n",
    "    print(f\"Top-3 accuracy: {top3_acc:.3%}, correct: {int(top3)}/{num_ttl}\")\n",
    "    print(f\"Top-5 accuracy: {top5_acc:.3%}, correct: {int(top5)}/{num_ttl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_seen_dataset\n",
      "Top-1 accuracy: 59.618%, correct: 1559/2615\n",
      "Top-3 accuracy: 73.652%, correct: 1926/2615\n",
      "Top-5 accuracy: 77.782%, correct: 2034/2615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Load and initialize CLAP\n",
    "    clap_model = CLAP(version = '2023', use_cuda=True)\n",
    "    # top1_acc, top1, top3_acc, top3, top5_acc, top5, num_ttl = inference(clap_model, unseen_classes, test_unseen_loader, \"cuda\")\n",
    "    top1_acc, top1, top3_acc, top3, top5_acc, top5, num_ttl = inference(clap_model, all_classes, test_unseen_loader, \"cuda\")\n",
    "    print(\"test_seen_dataset\")\n",
    "    print(f\"Top-1 accuracy: {top1_acc:.3%}, correct: {int(top1)}/{num_ttl}\")\n",
    "    print(f\"Top-3 accuracy: {top3_acc:.3%}, correct: {int(top3)}/{num_ttl}\")\n",
    "    print(f\"Top-5 accuracy: {top5_acc:.3%}, correct: {int(top5)}/{num_ttl}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
